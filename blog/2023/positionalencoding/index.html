<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> [P] Rotary Positional Embedding | Ricky Cheng </title> <meta name="author" content="Ricky Cheng"> <meta name="description" content="Notes about RoPE"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://rickysrcheng.github.io/blog/2023/positionalencoding/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Ricky Cheng </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">[P] Rotary Positional Embedding</h1> <p class="post-meta"> October 20, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/nlp"> <i class="fa-solid fa-hashtag fa-sm"></i> nlp</a>   <a href="/blog/tag/transformer"> <i class="fa-solid fa-hashtag fa-sm"></i> transformer</a>   <a href="/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> machine-learning</a>     ·   <a href="/blog/category/machine-learning"> <i class="fa-solid fa-tag fa-sm"></i> machine-learning</a>   <a href="/blog/category/nlp"> <i class="fa-solid fa-tag fa-sm"></i> nlp</a>   <a href="/blog/category/paper-reading"> <i class="fa-solid fa-tag fa-sm"></i> paper-reading</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="motivation">Motivation</h2> <ul> <li>Position and order in sequential data are significant in understanding the data itself <ul> <li>For example, a common sentence structure in English is “subject - verb - object”. So the order in which the nouns appear in relation to the verb is very important.</li> <li>Another example is the position and order of adjectives in relation to the noun it is describing</li> </ul> </li> <li>Past architectures, such as LSTMs and RNNs, implicitly encode positional data by continuously computing and passing along its hidden states to the next state</li> <li>Transformer models computes all the data in parallel with no mechanism that implicitly injects positional information to any data</li> <li>Thus, positional information must be applied externally</li> </ul> <h2 id="background-materials">Background Materials</h2> <h3 id="absolute-position-encoding">Absolute Position Encoding</h3> <ul> <li> <p>The original Transformer paper by <a href="https://arxiv.org/abs/1706.03762" rel="external nofollow noopener" target="_blank">Vaswani et al</a> employed absolute position encoding that is added to the vector after the embedding layer using the following formula</p> <p>\begin{align} PE_{(pos)} = \begin{cases} PE_{(pos, 2i)}&amp;=\sin\left(\frac{pos}{10000^{2i/d_{model}}}\right)\\\<br> PE_{(pos, 2i+1)}&amp;=\cos\left(\frac{pos}{10000^{2i/d_{model}}}\right) \end{cases} \end{align}</p> <p>where \(2i\) is the \(2i^{th}\) dimension, \(pos\) denote the position of the vector, and \(d_{model}\) is the size of embedding vector. Note that even dimensions use the sine function and odd dimensions use the cosine function.</p> </li> <li>Each dimension corresponds to a sinusoid with wavelengths ranging from \(2\pi\) to \(10000\cdot 2 \pi\). Thus, in the typical usecase, it is improbable that two tokens would share the same positional encoding.</li> <li>The position encoding can also be learned, but using a function may allow the model to extrapolate positional information for sequences with lengths longer than any lengths that the model was trained on.</li> </ul> <h3 id="complex-numbers">Complex Numbers</h3> <p>The underlying principles of RoPE relies on complex algebra. To be honest, I felt a little embarrassed because I had absolutely no understanding of the paper upon the first few reads until I went back to refresh my complex numbers.</p> <ul> <li>Complex numbers take the form of \(a + bi\), where \(a\) and \(b\) are real numbers and \(i=\sqrt{-1}\) is the imaginary unit.</li> <li> <p>We can also represent a complex number in polar form:</p> \[z = a + bi = r(\cos(\theta) + i\sin(\theta)) = re^{i\theta}\] <p>where \(r= \sqrt{a^2 + b^2}\) is called the radial component and \(\theta\) is called the angular component.</p> <p>The latter equality is called Euler’s formula: \(e^{i\theta} = \cos(\theta) + i\sin(\theta)\)</p> </li> <li> <p>Multiplications of two complex numbers works the same as algebraic multiplication using distributive property</p> \[(a + bi)(c + di) = (ac - bd) + (ad + bc)i\] <p>We can also convert the above to matrix form:</p> \[\begin{bmatrix} c &amp; -d\\ d &amp; c \end{bmatrix} \begin{bmatrix} a \\ b \end{bmatrix} = \begin{bmatrix} ac - bd \\ ad + bc \end{bmatrix}\] <p>Geometrically speaking, multiplication in complex domain can be thought of as an affine transformation consisting of a scale transformation and a rotation transformation. This can be seen when we replace \(c+ di\) with its polar form \(r(cos(\theta) + i\sin(\theta))\). The matrix form will look like:</p> \[r\cdot \begin{bmatrix} \cos(\theta) &amp; -\sin(\theta)\\ \sin(\theta) &amp; \cos(\theta) \end{bmatrix} \begin{bmatrix} a \\ b \end{bmatrix} = r\cdot \begin{bmatrix} a\cos(\theta) - b\sin(\theta) \\ a\sin(\theta) + b\cos(\theta) \end{bmatrix}\] <p>The above can be interpreted as scaling the complex number \(a + bi\) by \(r\) and then rotating it counter-clockwise by \(\theta\). Note that the matrix is a <a href="https://en.wikipedia.org/wiki/Rotation_matrix" rel="external nofollow noopener" target="_blank">standard rotation matrix</a> in Euclidean space.</p> </li> <li> <p>The inner product for the complex case is called the <em>Hermitian inner product.</em> Given \(u, v \in \mathbb{C}^n\), it is defined as:</p> \[\langle u, v \rangle = \sum_{i=1}^{n}u_i^*v_i\] <p>where \(u^*\) is the complex conjugate of \(u\).</p> </li> </ul> <h2 id="rotary-positional-embedding">Rotary Positional Embedding</h2> <ul> <li>Rotary Positional Embedding (RoPE) is a positional embedding technique proposed by <a href="https://arxiv.org/abs/2104.09864" rel="external nofollow noopener" target="_blank">Jianlin Su et al</a>.</li> <li> <p>The main idea behind RoPE was to find a way to encode absolute positional information into a vector whilst at the same time use relative positional information during self-attention. In other words given vectors \(x_m, x_n \in \mathbb{R}^d\), query and key functions \(f_k(\cdot), f_q(\cdot)\), and positional information \(m, n\), we want to find a function \(g(\cdot)\) that satisfies the following:</p> <p>\begin{equation} \label{eq:relativeposition} \left&lt; f_q(\mathbf{x_m}, m), f_k(\mathbf{x_n}, n)\right&gt; = g(\mathbf{x_m}, \mathbf{x_n}, m-n) \end{equation}</p> </li> <li> <p>The solution that RoPE introduces is to map the vector \(\mathbf{x}_m \in \mathbb{R}^d\) into \(d/2\) subspace in the complex domain \(\mathbb{C}^{d/2}\) by considering consecutive elements in \(\mathbf{x}_m\) as one complex number. As in</p> \[(x_1, x_2, \dots, x_{d-1}, x_d) \rightarrow (x_1 + i x_2 , \dots, x_{d-1} + i x_d )\] <p>This necessitates that the dimension of the original vector be even, which can be done by adding an additional dimension if the vector dimension is odd.</p> <p>We then inject positional information via rotation, which looks something like this:</p> \[f^{RoPE}(\mathbf{x}_m, m)_{j} = (x^{(2j)} + ix^{(2j+1)})e^{mi\theta_j}\] <p>Or in rotational matrix form:</p> \[f^{RoPE}(\mathbf{x}_m, m)_{j} = \begin{bmatrix} \cos(m\theta_j) &amp; -\sin(m\theta_j)\\ \sin(m\theta_j) &amp; \cos(m\theta_j) \end{bmatrix} \begin{bmatrix} x^{(2j)} \\ x^{(2j+1)} \end{bmatrix}\] <p>\(\theta_j\) is the sinusoidal wave for dimension \(j\) and is defined to be \(\theta_j = 10000^{-2j/d}\). As a shorthand, we can let \(R_{\theta_j, m}\) be the rotation matrix with the parameters \(\theta_j\) and \(m\).</p> <ul> <li> <p>The more general form of RoPE is given as</p> \[f^{RoPE}(\mathbf{x_m}, m) = R_{\Theta, m}\mathbf{x_m}\] <p>with the rotational matrix \(R_{\Theta, m}\) defined as:</p> \[R_{\Theta, m}= \begin{bmatrix} R_{\theta_0, m} &amp; &amp; &amp;\\ &amp; R_{\theta_1, m} &amp; \\ &amp; &amp; \ddots &amp;\\ &amp; &amp; &amp; R_{\theta_{d/2-1}, m}\\ \end{bmatrix}\] </li> </ul> </li> <li> <p>The above formulation of RoPE can then satisfy \eqref{eq:relativeposition}. For simplicity, we show the 2D case where \(\mathbf{x_m}, \mathbf{x_n} \in \mathbb{R}^2\):</p> \[\begin{align} \left&lt; f_q(\mathbf{x_m}, m), f_k(\mathbf{x_n}, n)\right&gt;_\mathbb{R} &amp;= \text{Re}(\left&lt; f^{RoPE}_q(\mathbf{x_m}, m), f^{RoPE}_k(\mathbf{x_n}, n)\right&gt;_\mathbb{C})\\ &amp;= \text{Re}(\hat{x}^*_m e^{-im\theta} \hat{x}_ne^{in\theta})\\ &amp;= \text{Re}\Big(\big((x^{(1)}_mx^{(1)}_n + x^{(2)}_mx^{(2)}_n) + i(-x^{(1)}_mx^{(2)}_n + x^{(2)}_mx^{(1)}_n)\big) e^{i(n-m)\theta}\Big)\\ &amp;= \cos\big((n-m)\theta\big) (x^{(1)}_mx^{(1)}_n + x^{(2)}_mx^{(2)}_n) \\ &amp;\quad\quad - \sin\big((n-m)\theta\big)(-x^{(1)}_mx^{(2)}_n + x^{(2)}_mx^{(1)}_n)\\ &amp;= \mathbf{x}^\intercal_\mathbf{m} R_{\theta, n-m} \mathbf{x_n}\\ &amp;= g(\mathbf{x_m}, \mathbf{x_n}, n-m) \end{align}\] <ul> <li>A big part of my confusion stems from the fact that this equivalence is given as true: \(\mathbf{q}\mathbf{k} = \text{Re}(\mathbf{q}^* \mathbf{k})\), which it is but I didn’t know how it got there since the vectors \(\mathbf{q}, \mathbf{k}\) are reused and the authors are relying on the readers to implicitly know if the vector is \(\mathbb{R}^d\) or \(\mathbb{C}^{d/2}\). If one isn’t being careful and assumed both vectors are in \(\mathbb{R}^d\), then one can observe that the complex conjugate of a real vector is itself, so \(qk = q^*k\), which means \(qk = \text{Re}(q^*k)\), but this isn’t the point being made in this paper.</li> </ul> </li> </ul> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Ricky Cheng. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>